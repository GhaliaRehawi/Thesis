{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from fnmatch import fnmatch\n",
    "from trainData_featExt_glcm import trainData_featExt_glcm\n",
    "from trainData_featExt_gabor import trainData_featExt_gabor\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from filtering.filters import Median\n",
    "from feature_extraction.glcm import Glcm\n",
    "from feature_extraction.gabor import Gabor\n",
    "import sklearn\n",
    "import time\n",
    "from gmm import Gmm\n",
    "from sklearn import preprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load training samples feature vector\n",
    "train_samples_feats_matrix_Gabor = np.load(\"train_samples_feats_matrix_Gabor.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load training samples feature vector\n",
    "valid_samples_feats_matrix_Gabor = np.load(\"valid_samples_feats_matrix_Gabor.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_samples_feats_matrix_Gabor = np.load(\"test_samples_feats_matrix_Gabor.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train a gaussian mixture model from training data\n",
    "t0 = time.time()\n",
    "gm_model = sklearn.mixture.GaussianMixture(n_components=1000, covariance_type='full', max_iter = 300)\n",
    "gm_model.fit(train_samples_feats_matrix_Gabor)\n",
    "print(\"traing time: \", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gm_model = pickle.load( open( 'GMM_Gabor_1000', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict labels of the new data points\n",
    "y_predict = gm_model.predict(valid_samples_feats_matrix_Gabor)\n",
    "#Predict novelty score of new data points\n",
    "y_predict_score = gm_model.score_samples(valid_samples_feats_matrix_Gabor)\n",
    "tmp = []\n",
    "#novelty_thresh = gm_model.score(train_samples_feats_matrix_LBP)\n",
    "x_predict_score = gm_model.score_samples(train_samples_feats_matrix_Gabor)\n",
    "novelty_thresh = np.amin(x_predict_score)\n",
    "\n",
    "# if data point belongs to the model then 1 else 0\n",
    "#tmp = np.zeros_like(y_predict_score)\n",
    "tmp = np.repeat(1, 10000)\n",
    "#74.2344062054\n",
    "tmp[y_predict_score < novelty_thresh] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict novelty score of new data points\n",
    "test_y_predict_score = gm_model.score_samples(test_samples_feats_matrix_Gabor)\n",
    "tmp2 = []\n",
    "#novelty_thresh = gm_model.score(train_samples_feats_matrix_LBP)\n",
    "#x_predict_score = gm_model.score_samples(train_samples_feats_matrix_Gabor)\n",
    "#novelty_thresh = np.amin(x_predict_score)\n",
    "\n",
    "# if data point belongs to the model then 1 else 0\n",
    "#tmp = np.zeros_like(y_predict_score)\n",
    "tmp2 = np.repeat(1, 10000)\n",
    "#74.2344062054\n",
    "tmp2[test_y_predict_score < 74.2344062054] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ground truth\n",
    "y1 = np.repeat(1, 6000) #normal\n",
    "y2 = np.repeat(0, 4000) #abnormal\n",
    "y = np.concatenate((y1,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_binary = sklearn.metrics.f1_score(y, tmp, pos_label = 0, average = 'binary')\n",
    "f1_macro = sklearn.metrics.f1_score(y, tmp, average = 'macro')\n",
    "auc = sklearn.metrics.roc_auc_score(y, y_predict_score)\n",
    "Math_Cof = sklearn.metrics.matthews_corrcoef(y, tmp) \n",
    "kappa = sklearn.metrics.cohen_kappa_score(y, tmp)\n",
    "print(\"kappa \", kappa)\n",
    "tn, fp, fn, tp  = sklearn.metrics.confusion_matrix(y, tmp).ravel()\n",
    "print (\"f1_binary: \", f1_binary, \"f1_macro: \", f1_macro, \"MAth_cof: \", Math_Cof , \" auc: \", auc)\n",
    "print(\"confusion matrix\", tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get different thresholds value from ROC with corresponding F1_score and AUC\n",
    "fpr,tpr,thresh = sklearn.metrics.roc_curve(y, y_predict_score)\n",
    "for t, thres in enumerate (thresh) :\n",
    "    tmp = np.repeat(1,10000)\n",
    "    tmp[y_predict_score < thres] = 0\n",
    "    f1 = sklearn.metrics.f1_score(y, tmp, average = 'macro')\n",
    "    print (\"f1: \", f1, \"thres: \", thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: off\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import matplotlib\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "fpr,tpr,thresh = sklearn.metrics.roc_curve(y,y_predict_score)\n",
    "test_fpr,test_tpr,test_thresh = sklearn.metrics.roc_curve(y,test_y_predict_score)\n",
    "#print ('true positive rate: ',tpr )\n",
    "#print ('true positive rate: ',1 - fpr )\n",
    "f,ax = pl.subplots(1,1)\n",
    "ax.plot(fpr,tpr,label=\"GMM-Validation\")\n",
    "ax.plot(test_fpr,test_tpr,label=\"GMM-test\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set_title(\"ROC curves\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "# these are matplotlib.patch.Patch properties\n",
    "#props = dict(boxstyle='square', facecolor='white', alpha=0.5)\n",
    "\n",
    "#textstr = '$F1-binary=%.2f$\\n$F1-macro=%.2f$\\n$math-corcoeffient=%.2f$\\n$AUC=%.2f$'%(0.66, 0.74, 0.51, 0.83)\n",
    "# place a text box in upper left in axes coords\n",
    "#ax.text(0.95, 0.2, textstr, transform=ax.transAxes, fontsize=14,\n",
    "#    horizontalalignment='right', verticalalignment='bottom', bbox=props)\n",
    "\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.savefig('GMM_Gabor_test-vs-validation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
